{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "660ce795-9307-4c2c-98a1-beabcb36c740",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-0/basics.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/56295530-getting-set-up-video-guide)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef597741-3211-4ecc-92f7-f58023ee237e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# –ê–∫–∞–¥–µ–º–∏—è LangChain\n",
    "\n",
    "–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤ –ê–∫–∞–¥–µ–º–∏—é LangChain!\n",
    "\n",
    "## –ö–æ–Ω—Ç–µ–∫—Å—Ç\n",
    "\n",
    "–í LangChain –º—ã —Å—Ç—Ä–µ–º–∏–º—Å—è —É–ø—Ä–æ—Å—Ç–∏—Ç—å —Å–æ–∑–¥–∞–Ω–∏–µ LLM-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π. –û–¥–Ω–∏–º –∏–∑ —Ç–∏–ø–æ–≤ LLM-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π, –∫–æ—Ç–æ—Ä—ã–µ –≤—ã –º–æ–∂–µ—Ç–µ —Å–æ–∑–¥–∞–≤–∞—Ç—å, —è–≤–ª—è—é—Ç—Å—è –∞–≥–µ–Ω—Ç—ã. **–ò–Ω—Ç–µ—Ä–µ—Å –∫ —Å–æ–∑–¥–∞–Ω–∏—é –∞–≥–µ–Ω—Ç–æ–≤** –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –≤—ã—Ä–æ—Å, –ø–æ—Å–∫–æ–ª—å–∫—É –æ–Ω–∏ —Å–ø–æ—Å–æ–±–Ω—ã –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞—Ç—å —à–∏—Ä–æ–∫–∏–π —Å–ø–µ–∫—Ç—Ä –∑–∞–¥–∞—á, –∫–æ—Ç–æ—Ä—ã–µ —Ä–∞–Ω–µ–µ –±—ã–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã.\n",
    "\n",
    "–û–¥–Ω–∞–∫–æ –Ω–∞ –ø—Ä–∞–∫—Ç–∏–∫–µ —Å–æ–∑–¥–∞–Ω–∏–µ —Å–∏—Å—Ç–µ–º, **—É—Å—Ç–æ–π—á–∏–≤–æ** —Å–ø—Ä–∞–≤–ª—è—é—â–∏—Ö—Å—è —Å —ç—Ç–∏–º–∏ –∑–∞–¥–∞—á–∞–º–∏, –æ–∫–∞–∑—ã–≤–∞–µ—Ç—Å—è –∫—Ä–∞–π–Ω–µ —Å–ª–æ–∂–Ω—ã–º. –†–∞–±–æ—Ç–∞—è —Å –Ω–∞—à–∏–º–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º–∏ –Ω–∞–¥ **–≤–Ω–µ–¥—Ä–µ–Ω–∏–µ–º –∞–≥–µ–Ω—Ç–æ–≤ –≤ –ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω—É—é —ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏—é**, –º—ã –æ—Å–æ–∑–Ω–∞–ª–∏, —á—Ç–æ —á–∞—Å—Ç–æ —Ç—Ä–µ–±—É–µ—Ç—Å—è –±–æ–ª–µ–µ **—Ç–æ–Ω–∫–∏–π –∫–æ–Ω—Ç—Ä–æ–ª—å**. –ù–∞–ø—Ä–∏–º–µ—Ä, –º–æ–∂–µ—Ç –ø–æ—Ç—Ä–µ–±–æ–≤–∞—Ç—å—Å—è, —á—Ç–æ–±—ã –∞–≥–µ–Ω—Ç –≤—Å–µ–≥–¥–∞ —Å–Ω–∞—á–∞–ª–∞ –≤—ã–∑—ã–≤–∞–ª –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª —Ä–∞–∑–ª–∏—á–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Å–≤–æ–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è.\n",
    "\n",
    "–î–ª—è —Ä–µ—à–µ–Ω–∏—è —ç—Ç–æ–π –ø—Ä–æ–±–ª–µ–º—ã –º—ã —Å–æ–∑–¥–∞–ª–∏ [LangGraph](https://docs.langchain.com/oss/python/langgraph/overview) ‚Äî –ø–ª–∞—Ç—Ñ–æ—Ä–º—É –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –∞–≥–µ–Ω—Ç–Ω—ã—Ö –∏ –º—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π. –í –æ—Ç–ª–∏—á–∏–µ –æ—Ç –ø–∞–∫–µ—Ç–∞ LangChain, –æ—Å–Ω–æ–≤–Ω–∞—è —Ñ–∏–ª–æ—Å–æ—Ñ–∏—è LangGraph –∑–∞–∫–ª—é—á–∞–µ—Ç—Å—è –≤ —Ç–æ–º, —á—Ç–æ–±—ã –ø–æ–º–æ—á—å —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞–º –ø–æ–≤—ã—Å–∏—Ç—å **—Ç–æ—á–Ω–æ—Å—Ç—å –∏ —É–ø—Ä–∞–≤–ª—è–µ–º–æ—Å—Ç—å** —Ä–∞–±–æ—á–∏—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –∞–≥–µ–Ω—Ç–æ–≤, —á—Ç–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ —Ä–µ–∞–ª—å–Ω—ã—Ö —Å–∏—Å—Ç–µ–º.\n",
    "\n",
    "## –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –∫—É—Ä—Å–∞\n",
    "\n",
    "–ö—É—Ä—Å —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ –Ω–∞–±–æ—Ä–∞ –º–æ–¥—É–ª–µ–π, –∫–∞–∂–¥—ã–π –∏–∑ –∫–æ—Ç–æ—Ä—ã—Ö –ø–æ—Å–≤—è—â–µ–Ω –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–π —Ç–µ–º–µ, —Å–≤—è–∑–∞–Ω–Ω–æ–π —Å LangGraph. –î–ª—è –∫–∞–∂–¥–æ–≥–æ –º–æ–¥—É–ª—è –ø—Ä–µ–¥—É—Å–º–æ—Ç—Ä–µ–Ω–∞ –ø–∞–ø–∫–∞ —Å —Å–µ—Ä–∏–µ–π –±–ª–æ–∫–Ω–æ—Ç–æ–≤. –ö –∫–∞–∂–¥–æ–º—É –±–ª–æ–∫–Ω–æ—Ç—É –ø—Ä–∏–ª–∞–≥–∞–µ—Ç—Å—è –≤–∏–¥–µ–æ —Å –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ–º –∫–æ–Ω—Ü–µ–ø—Ü–∏–π, –Ω–æ –ø—Ä–∏ —ç—Ç–æ–º –±–ª–æ–∫–Ω–æ—Ç—ã —Å–∞–º–æ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã ‚Äî –æ–Ω–∏ —Å–æ–¥–µ—Ä–∂–∞—Ç –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–æ—è—Å–Ω–µ–Ω–∏—è –∏ –º–æ–≥—É—Ç –∏–∑—É—á–∞—Ç—å—Å—è –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç –≤–∏–¥–µ–æ. –ö–∞–∂–¥–∞—è –ø–∞–ø–∫–∞ –º–æ–¥—É–ª—è —Ç–∞–∫–∂–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –ø–∞–ø–∫—É \"studio\" —Å –Ω–∞–±–æ—Ä–æ–º –≥—Ä–∞—Ñ–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–∂–Ω–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å –≤ [LangSmith Studio](https://docs.langchain.com/langsmith/quick-start-studio) ‚Äî –Ω–∞—à—É IDE-—Å—Ä–µ–¥—É –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π LangGraph.\n",
    "\n",
    "## –ù–∞—Å—Ç—Ä–æ–π–∫–∞\n",
    "\n",
    "–ü–µ—Ä–µ–¥ –Ω–∞—á–∞–ª–æ–º —Ä–∞–±–æ—Ç—ã –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –∏–∑ —Ñ–∞–π–ª–∞ README.md –ø—Ä–æ–µ–∫—Ç–∞, —á—Ç–æ–±—ã —Å–æ–∑–¥–∞—Ç—å –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ –∏ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏.\n",
    "\n",
    "## LLM-–º–æ–¥–µ–ª–∏\n",
    "\n",
    "–í —ç—Ç–æ–º –∫—É—Ä—Å–µ –º—ã –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å LLM-–º–æ–¥–µ–ª–∏, –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–∏–Ω–∏–º–∞—é—Ç –Ω–∞ –≤—Ö–æ–¥ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–π –∏ –≤–æ–∑–≤—Ä–∞—â–∞—é—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –≤ –∫–∞—á–µ—Å—Ç–≤–µ –≤—ã—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö. LangChain –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –º–Ω–æ–∂–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–µ–π —á–µ—Ä–µ–∑ [—Å—Ç–æ—Ä–æ–Ω–Ω–∏–µ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏](https://docs.langchain.com/oss/python/integrations/chat). –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤ –∫—É—Ä—Å–µ –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è [ChatOpenAI](https://docs.langchain.com/oss/python/integrations/chat/openai), –ø–æ—Å–∫–æ–ª—å–∫—É —ç—Ç–∞ –º–æ–¥–µ–ª—å –ø–æ–ø—É–ª—è—Ä–Ω–∞ –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞. –ö–∞–∫ —É–∂–µ —É–ø–æ–º–∏–Ω–∞–ª–æ—Å—å, —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —É –≤–∞—Å –µ—Å—Ç—å `OPENAI_API_KEY`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f9a52c8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langchain_openai langchain_mistralai langchain_core langchain_community langchain-tavily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d709bc2-14c4-4c1e-95cf-cf870ee5e8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip list | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2a15227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "MISTRAL_API_KEY:  ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
     ]
    }
   ],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "# API –∫–ª—é—á–∏\n",
    "KEY = \"MISTRAL_API_KEY\"\n",
    "# KEY = \"OPENAI_API_KEY\"\n",
    "\n",
    "_set_env(KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a326f35b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "[–ó–¥–µ—Å—å](https://docs.langchain.com/oss/python/langchain/models) –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–æ –ø–æ–ª–µ–∑–Ω–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –≤—Å–µ–º –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è–º —Ä–∞–±–æ—Ç—ã —Å —á–∞—Ç-–º–æ–¥–µ–ª—è–º–∏, –∞ –Ω–∏–∂–µ –º—ã –ø–æ–∫–∞–∂–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫–ª—é—á–µ–≤—ã—Ö –º–æ–º–µ–Ω—Ç–æ–≤. –ï—Å–ª–∏ –≤—ã –≤—ã–ø–æ–ª–Ω–∏–ª–∏ `pip install -r requirements.txt` –∫–∞–∫ —É–∫–∞–∑–∞–Ω–æ –≤ README, –∑–Ω–∞—á–∏—Ç, —É –≤–∞—Å —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–∞–∫–µ—Ç \"langchain-openai\". –° –µ–≥–æ –ø–æ–º–æ—â—å—é –º—ã –º–æ–∂–µ–º —Å–æ–∑–¥–∞—Ç—å —ç–∫–∑–µ–º–ø–ª—è—Ä –Ω–∞—à–µ–π –º–æ–¥–µ–ª–∏ `ChatOpenAI`. –° —Ü–µ–Ω–∞–º–∏ –Ω–∞ —Ä–∞–∑–ª–∏—á–Ω—ã–µ –º–æ–¥–µ–ª–∏ –º–æ–∂–Ω–æ –æ–∑–Ω–∞–∫–æ–º–∏—Ç—å—Å—è [–∑–¥–µ—Å—å](https://openai.com/api/pricing/). –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤ –±–ª–æ–∫–Ω–æ—Ç–∞—Ö –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è \"gpt-4o\", –ø–æ—Å–∫–æ–ª—å–∫—É —ç—Ç–∞ –º–æ–¥–µ–ª—å –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ —Å–æ—á–µ—Ç–∞–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞, —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –∏ —Å–∫–æ—Ä–æ—Å—Ç–∏, –Ω–æ –≤—ã —Ç–∞–∫–∂–µ –º–æ–∂–µ—Ç–µ –≤—ã–±—Ä–∞—Ç—å –±–æ–ª–µ–µ –±—é–¥–∂–µ—Ç–Ω—É—é —Å–µ—Ä–∏—é \"gpt-3.5\" –∏–ª–∏ –±–æ–ª–µ–µ –Ω–æ–≤—ã–µ –º–æ–¥–µ–ª–∏.\n",
    "\n",
    "–°—É—â–µ—Å—Ç–≤—É–µ—Ç [–Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤](https://docs.langchain.com/oss/python/langchain/models#parameters), –∫–æ—Ç–æ—Ä—ã–µ –º–æ–∂–Ω–æ –∑–∞–¥–∞—Ç—å –¥–ª—è —á–∞—Ç-–º–æ–¥–µ–ª–µ–π. –î–≤–∞ –Ω–∞–∏–±–æ–ª–µ–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–Ω—ã—Ö:\n",
    "\n",
    "* `model`: –Ω–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
    "* `temperature` (**—Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞**) ‚Äî –ø–∞—Ä–∞–º–µ—Ç—Ä —Å—ç–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏—è\n",
    "\n",
    "`temperature` —É–ø—Ä–∞–≤–ª—è–µ—Ç —Å—Ç–µ–ø–µ–Ω—å—é —Å–ª—É—á–∞–π–Ω–æ—Å—Ç–∏ –∏–ª–∏ –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏ –≤—ã—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–∏. –ù–∏–∑–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã (–±–ª–∏–∑–∫–æ–µ –∫ 0) –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –±–æ–ª–µ–µ –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∏ —Ü–µ–ª–µ–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã, —á—Ç–æ —Ö–æ—Ä–æ—à–æ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –∑–∞–¥–∞—á, —Ç—Ä–µ–±—É—é—â–∏—Ö —Ç–æ—á–Ω–æ—Å—Ç–∏ –∏ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–π –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç–∏. –í—ã—Å–æ–∫–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ (–±–ª–∏–∑–∫–∞—è –∫ 1) –ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω–∞ –¥–ª—è —Ç–≤–æ—Ä—á–µ—Å–∫–∏—Ö –∑–∞–¥–∞—á –∏–ª–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e19a54d3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from langchain_openai import ChatOpenAI\n",
    "from langchain_mistralai import ChatMistralAI\n",
    "mistral_small_latest = ChatMistralAI(model=\"mistral-small-latest\", temperature=0.1)\n",
    "mistral_medium_latest = ChatMistralAI(model=\"mistral-medium-latest\", temperature=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28450d1b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "–£ LLM-–º–æ–¥–µ–ª–µ–π –≤ LangChain –µ—Å—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ [—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –º–µ—Ç–æ–¥–æ–≤](https://reference.langchain.com/python/langchain_core/runnables). –í –æ—Å–Ω–æ–≤–Ω–æ–º –º—ã –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:\n",
    "\n",
    "* [stream](https://docs.langchain.com/oss/python/langchain/models#stream) ‚Äî **–ø–æ—Ç–æ–∫–æ–≤–∞—è –ø–µ—Ä–µ–¥–∞—á–∞** –æ—Ç–≤–µ—Ç–∞ –ø–æ –º–µ—Ä–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤\n",
    "* [invoke](https://docs.langchain.com/oss/python/langchain/models#invoke) ‚Äî **–≤—ã–∑–æ–≤** –≤—Å–µ–π —Ü–µ–ø–æ—á–∫–∏ –Ω–∞ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "\n",
    "–ö–∞–∫ —É–∂–µ —É–ø–æ–º–∏–Ω–∞–ª–æ—Å—å, –º–æ–¥–µ–ª–∏ —Ä–∞–±–æ—Ç–∞—é—Ç —Å [—Å–æ–æ–±—â–µ–Ω–∏—è–º–∏](https://docs.langchain.com/oss/python/langchain/messages) –≤ –∫–∞—á–µ—Å—Ç–≤–µ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö. –°–æ–æ–±—â–µ–Ω–∏—è —Å–æ–¥–µ—Ä–∂–∞—Ç —Ä–æ–ª—å (–∫–æ—Ç–æ—Ä–∞—è –æ–ø–∏—Å—ã–≤–∞–µ—Ç –æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—è) –∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ. –ü–æ–¥—Ä–æ–±–Ω–µ–µ –º—ã —Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º —ç—Ç–æ –ø–æ–∑–∂–µ, –∞ —Å–µ–π—á–∞—Å –¥–∞–≤–∞–π—Ç–µ —Ä–∞–∑–±–µ—Ä–µ–º –æ—Å–Ω–æ–≤—ã."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1280e1b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! üòä How can I assist you today?', additional_kwargs={}, response_metadata={'token_usage': {'prompt_tokens': 5, 'total_tokens': 18, 'completion_tokens': 13}, 'model_name': 'mistral-small-latest', 'model': 'mistral-small-latest', 'finish_reason': 'stop', 'model_provider': 'mistralai'}, id='lc_run--d34abbfe-9279-4eb2-9900-1e7d650b78d3-0', usage_metadata={'input_tokens': 5, 'output_tokens': 13, 'total_tokens': 18})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# –°–æ–∑–¥–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ\n",
    "msg = HumanMessage(content=\"Hello world\", name=\"Lance\")\n",
    "\n",
    "# –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π\n",
    "messages = [msg]\n",
    "\n",
    "# –í—ã–∑–æ–≤ –º–æ–¥–µ–ª–∏ —Å–æ —Å–ø–∏—Å–∫–æ–º —Å–æ–æ–±—â–µ–Ω–∏–π\n",
    "mistral_small_latest.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac73e4c",
   "metadata": {},
   "source": [
    "–ú—ã –ø–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç `AIMessage`. –¢–∞–∫–∂–µ –æ–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ, —á—Ç–æ –º—ã –º–æ–∂–µ–º –ø—Ä–æ—Å—Ç–æ –≤—ã–∑–≤–∞—Ç—å –º–æ–¥–µ–ª—å, **–ø–µ—Ä–µ–¥–∞–≤ –µ–π —Å—Ç—Ä–æ–∫—É**. –ö–æ–≥–¥–∞ —Å—Ç—Ä–æ–∫–∞ –ø–µ—Ä–µ–¥–∞–µ—Ç—Å—è –Ω–∞ –≤—Ö–æ–¥, –æ–Ω–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç—Å—è –≤ `HumanMessage` –∏ –∑–∞—Ç–µ–º –ø–µ—Ä–µ–¥–∞–µ—Ç—Å—è –≤ –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f27c6c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! üòä How can I assist you today?', additional_kwargs={}, response_metadata={'token_usage': {'prompt_tokens': 5, 'total_tokens': 18, 'completion_tokens': 13}, 'model_name': 'mistral-small-latest', 'model': 'mistral-small-latest', 'finish_reason': 'stop', 'model_provider': 'mistralai'}, id='lc_run--1e4485b2-2620-4596-9969-6738446c21f1-0', usage_metadata={'input_tokens': 5, 'output_tokens': 13, 'total_tokens': 18})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mistral_small_latest.invoke(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdc2f0ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello, World! üåç‚ú®\\n\\nHow can I assist you today? üòä\\n\\n(If you\\'re just starting with programming, here\\'s a classic \"Hello, World!\" example in Python:)\\n\\n```python\\nprint(\"Hello, World!\")\\n```', additional_kwargs={}, response_metadata={'token_usage': {'prompt_tokens': 5, 'total_tokens': 61, 'completion_tokens': 56}, 'model_name': 'mistral-medium-latest', 'model': 'mistral-medium-latest', 'finish_reason': 'stop', 'model_provider': 'mistralai'}, id='lc_run--a2b25932-780f-492a-8a1e-f0476d85a5d4-0', usage_metadata={'input_tokens': 5, 'output_tokens': 56, 'total_tokens': 61})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mistral_medium_latest.invoke(\"hello world\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582c0e5a",
   "metadata": {},
   "source": [
    "–ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –æ–¥–∏–Ω–∞–∫–æ–≤ –¥–ª—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π, –∏ –º–æ–¥–µ–ª–∏ –æ–±—ã—á–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—Ç—Å—è –æ–¥–∏–Ω —Ä–∞–∑ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –∫–∞–∂–¥–æ–≥–æ —Ñ–∞–π–ª–∞ (Jupyter Notebook).\n",
    "\n",
    "–¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, –≤—ã –º–æ–∂–µ—Ç–µ –ª–µ–≥–∫–æ –ø–µ—Ä–µ–∫–ª—é—á–∞—Ç—å—Å—è –º–µ–∂–¥—É –º–æ–¥–µ–ª—è–º–∏, –Ω–µ –∏–∑–º–µ–Ω—è—è –∏—Å—Ö–æ–¥–Ω—ã–π –∫–æ–¥, –µ—Å–ª–∏ –ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ—Ç–µ –¥—Ä—É–≥–æ–≥–æ –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad0069a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –ø–æ–∏—Å–∫–∞\n",
    "\n",
    "–í—ã —Ç–∞–∫–∂–µ —É–≤–∏–¥–∏—Ç–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ [Tavily](https://tavily.com/) –≤ —Ñ–∞–π–ª–µ README. –≠—Ç–æ –ø–æ–∏—Å–∫–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞, –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –±–æ–ª—å—à–∏–º–∏ —è–∑—ã–∫–æ–≤—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏ (LLM) –∏ RAG, —Ü–µ–ª—å—é –∫–æ—Ç–æ—Ä–æ–π —è–≤–ª—è–µ—Ç—Å—è –æ–±–µ—Å–ø–µ—á–µ–Ω–∏–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã—Ö, –±—ã—Å—Ç—Ä—ã—Ö –∏ —É—Å—Ç–æ–π—á–∏–≤—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞. –ö–∞–∫ —É–∂–µ —É–ø–æ–º–∏–Ω–∞–ª–æ—Å—å, –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å—Å—è –æ—á–µ–Ω—å –ø—Ä–æ—Å—Ç–æ, –∏ —Å–µ—Ä–≤–∏—Å –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç —â–µ–¥—Ä—ã–π –±–µ—Å–ø–ª–∞—Ç–Ω—ã–π —Ç–∞—Ä–∏—Ñ. –ù–µ–∫–æ—Ç–æ—Ä—ã–µ —É—Ä–æ–∫–∏ (–≤ –ú–æ–¥—É–ª–µ 4) –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏—Å–ø–æ–ª—å–∑—É—é—Ç Tavily, –Ω–æ, –∫–æ–Ω–µ—á–Ω–æ, –≤—ã –º–æ–∂–µ—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∏ –¥—Ä—É–≥–∏–µ –ø–æ–∏—Å–∫–æ–≤—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã, –µ—Å–ª–∏ –∑–∞—Ö–æ—Ç–∏—Ç–µ –∏–∑–º–µ–Ω–∏—Ç—å –∫–æ–¥ –ø–æ–¥ —Å–≤–æ–∏ –Ω—É–∂–¥—ã."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "091dff13",
   "metadata": {},
   "outputs": [],
   "source": [
    "_set_env(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52d69da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_tavily import TavilySearch  # updated at 1.0\n",
    "\n",
    "tavily_search = TavilySearch(max_results=3)\n",
    "\n",
    "data = tavily_search.invoke({\"query\": \"What is LangGraph?\"})\n",
    "search_docs = data.get(\"results\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d06f87e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://www.datacamp.com/tutorial/langgraph-tutorial',\n",
       "  'title': 'LangGraph Tutorial: What Is LangGraph and How to Use It?',\n",
       "  'content': 'LangGraph is a library within the LangChain ecosystem that provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured and efficient manner. By managing the flow of data and the sequence of operations, LangGraph allows developers to focus on the high-level logic of their applications rather than the intricacies of agent coordination. Whether you need a chatbot that can handle various types of user requests or a multi-agent system that performs complex tasks, LangGraph provides the tools to build exactly what you need. LangGraph significantly simplifies the development of complex LLM applications by providing a structured framework for managing state and coordinating agent interactions.',\n",
       "  'score': 0.9581988,\n",
       "  'raw_content': None},\n",
       " {'url': 'https://www.geeksforgeeks.org/machine-learning/what-is-langgraph/',\n",
       "  'title': 'What is LangGraph? - GeeksforGeeks',\n",
       "  'content': 'LangGraph is an open-source framework built by LangChain that streamlines the creation and management of AI agent workflows. By treating workflows as interconnected nodes and edges, LangGraph offers a scalable, transparent and developer-friendly way to design advanced AI systems ranging from simple chatbots to multi-agent system. * ****Enhanced decision-making:**** Models relationships between nodes, enabling AI agents to learn from past actions and feedback. * ****langgraph:**** Framework for building graph-based AI workflows. * Build the workflow graph using LangGraph, adding nodes for classification and response, connecting them with edges and compiling the app. * Send each input through the workflow graph and returns the bot‚Äôs response, either a greeting or an AI-powered answer.',\n",
       "  'score': 0.95067275,\n",
       "  'raw_content': None},\n",
       " {'url': 'https://langchain-ai.github.io/langgraph/concepts/why-langgraph/',\n",
       "  'title': 'Learn LangGraph basics - Overview',\n",
       "  'content': 'Trusted by companies shaping the future of agents‚Äî including Klarna, Replit, Elastic, and more‚Äî LangGraph is a low-level orchestration framework and runtime for building, managing, and deploying long-running, stateful agents. LangGraph is very low-level, and focused entirely on agent **orchestration**. Before using LangGraph, we recommend you familiarize yourself with some of the components used to build agents, starting with models and tools. LangGraph is focused on the underlying capabilities important for agent orchestration: durable execution, streaming, human-in-the-loop, and more. LangGraph provides low-level supporting infrastructure for *any* long-running, stateful workflow or agent. While LangGraph can be used standalone, it also integrates seamlessly with any LangChain product, giving developers a full suite of tools for building agents. Contains agent abstractions built on top of LangGraph.',\n",
       "  'score': 0.94911116,\n",
       "  'raw_content': None}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7545f4-aeb7-4b03-91f5-df3e021fe960",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
