{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1012a788",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-3/breakpoints.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239469-lesson-2-breakpoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4aa16f5-abc8-4ed3-8a71-54837fe46917",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Точки прерывания (Breakpoints)\n",
    "\n",
    "## Итоги предыдущего раздела\n",
    "\n",
    "Для реализации `human-in-the-loop` (человек в цикле) часто требуется видеть выводы графа по мере его выполнения.\n",
    "\n",
    "Мы заложили основу для этого с помощью потоковой передачи.\n",
    "\n",
    "## Цели текущего раздела\n",
    "\n",
    "Теперь давайте обсудим мотивацию для `human-in-the-loop`:\n",
    "\n",
    "(1) `Утверждение` - Мы можем прервать нашего агента, показать состояние пользователю и позволить пользователю принять действие\n",
    "\n",
    "(2) `Отладка` - Мы можем перемотать граф, чтобы воспроизвести или избежать проблем\n",
    "\n",
    "(3) `Редактирование` - Вы можете изменить состояние\n",
    "\n",
    "LangGraph предлагает несколько способов получения или обновления состояния агента для поддержки различных рабочих процессов `human-in-the-loop`.\n",
    "\n",
    "Сначала мы представим [точки прерывания](https://docs.langchain.com/oss/python/langgraph/interrupts#debugging-with-interrupts), которые предоставляют простой способ остановить граф на определенных шагах.\n",
    "\n",
    "Мы покажем, как это позволяет реализовать `утверждение` пользователем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35842345-0694-4f0a-aa62-7d4898abf653",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langgraph langchain_mistralai langgraph_sdk langgraph-prebuilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67d91f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "MISTRAL_API_KEY:  ········\n"
     ]
    }
   ],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"MISTRAL_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d8b4cd-e3ff-48cc-b7b2-f83fadb1c86b",
   "metadata": {},
   "source": [
    "## Точки прерывания для утверждения человеком\n",
    "\n",
    "Давайте вернемся к простому агенту, с которым мы работали в Модуле 1.\n",
    "\n",
    "Предположим, что мы обеспокоены использованием инструментов: мы хотим утверждать использование агентом любого из его инструментов.\n",
    "\n",
    "Все, что нам нужно сделать, это просто скомпилировать граф с `interrupt_before=[\"tools\"]`, где `tools` - это наш узел инструментов.\n",
    "\n",
    "Это означает, что выполнение будет прервано перед узлом `tools`, который выполняет вызов инструмента."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b94d1a90-2fe3-4b2a-a901-3bdb89e37edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mistralai import ChatMistralAI\n",
    "\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "# This will be a tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "def divide(a: int, b: int) -> float:\n",
    "    \"\"\"Divide a by b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a / b\n",
    "\n",
    "tools = [add, multiply, divide]\n",
    "llm = ChatMistralAI(model=\"mistral-small-latest\")\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac06feae-d12b-490b-95e7-38cf40b74202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.graph import START, StateGraph\n",
    "from langgraph.prebuilt import tools_condition, ToolNode\n",
    "\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "# System message\n",
    "sys_msg = SystemMessage(content=\"You are a helpful assistant tasked with performing arithmetic on a set of inputs.\")\n",
    "\n",
    "# Node\n",
    "def assistant(state: MessagesState):\n",
    "   return {\"messages\": [llm_with_tools.invoke([sys_msg] + state[\"messages\"])]}\n",
    "\n",
    "# Graph\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# Define nodes: these do the work\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "# Define edges: these determine the control flow\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    # If the latest message (result) from assistant is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from assistant is a not a tool call -> tools_condition routes to END\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = builder.compile(interrupt_before=[\"tools\"], checkpointer=memory)\n",
    "\n",
    "# Show\n",
    "display(Image(graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a783efac-46a9-4fb4-a1c6-a11b02540448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiply 2 and 3\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (EeCRLk5Yy)\n",
      " Call ID: EeCRLk5Yy\n",
      "  Args:\n",
      "    a: 2\n",
      "    b: 3\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "initial_input = {\"messages\": HumanMessage(content=\"Multiply 2 and 3\")}\n",
    "\n",
    "# Thread\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Run the graph until the first interruption\n",
    "for event in graph.stream(initial_input, thread, stream_mode=\"values\"):\n",
    "    event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d49669-b1a5-42c2-bdb8-052da89bd7c4",
   "metadata": {},
   "source": [
    "Мы можем получить состояние и посмотреть, какой узел должен быть вызван следующим.\n",
    "\n",
    "Это удобный способ увидеть, что граф был прерван."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61569596-8342-4a37-9c99-e3a9dccb18ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tools',)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = graph.get_state(thread)\n",
    "state.next"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2fea0fb5-3145-4f34-bcc0-9c9e8972d6b4",
   "metadata": {},
   "source": [
    "Теперь покажем полезный приём.\n",
    "\n",
    "Когда мы вызываем граф с `None`, он просто продолжит выполнение с последней контрольной точки состояния!\n",
    "\n",
    "![breakpoints.jpg](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbae7985b747dfed67775d_breakpoints1.png)\n",
    "\n",
    "Для ясности: LangGraph повторно выдаст текущее состояние, которое содержит `AIMessage` с вызовом инструмента.\n",
    "\n",
    "Затем он продолжит выполнение следующих шагов в графе, начиная с узла инструментов.\n",
    "\n",
    "Мы видим, что узел инструментов выполняется с этим вызовом, и результат передаётся обратно в чат-модель для получения окончательного ответа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "896a5f41-7386-4bfa-a78e-3e6ca5e26641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (EeCRLk5Yy)\n",
      " Call ID: EeCRLk5Yy\n",
      "  Args:\n",
      "    a: 2\n",
      "    b: 3\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "6\n"
     ]
    },
    {
     "ename": "HTTPStatusError",
     "evalue": "Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"object\":\"error\",\"message\":\"Service tier capacity exceeded for this model.\",\"type\":\"service_tier_capacity_exceeded\",\"param\":null,\"code\":\"3505\"}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPStatusError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpretty_print\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/langchain-academy/venv/lib/python3.11/site-packages/langgraph/pregel/main.py:2679\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2677\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2678\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2679\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2680\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2681\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2682\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2683\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2684\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2685\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2686\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2687\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2688\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2689\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/langchain-academy/venv/lib/python3.11/site-packages/langgraph/pregel/_runner.py:167\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    165\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/langchain-academy/venv/lib/python3.11/site-packages/langgraph/pregel/_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/langchain-academy/venv/lib/python3.11/site-packages/langgraph/_internal/_runnable.py:656\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    654\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m656\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    658\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/langchain-academy/venv/lib/python3.11/site-packages/langgraph/_internal/_runnable.py:400\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    398\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36massistant\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34massistant\u001b[39m(state: MessagesState):\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m    \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[43mllm_with_tools\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43msys_msg\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m]}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/langchain-academy/venv/lib/python3.11/site-packages/langchain_core/runnables/base.py:5489\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5482\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5483\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5484\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5487\u001b[39m     **kwargs: Any | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   5488\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5489\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5490\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5491\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5492\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5493\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/langchain-academy/venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:382\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    368\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    370\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    375\u001b[39m     **kwargs: Any,\n\u001b[32m    376\u001b[39m ) -> AIMessage:\n\u001b[32m    377\u001b[39m     config = ensure_config(config)\n\u001b[32m    378\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    379\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAIMessage\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    380\u001b[39m         cast(\n\u001b[32m    381\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m382\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    392\u001b[39m         ).message,\n\u001b[32m    393\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/langchain-academy/venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:1091\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1082\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1083\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1084\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1088\u001b[39m     **kwargs: Any,\n\u001b[32m   1089\u001b[39m ) -> LLMResult:\n\u001b[32m   1090\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1091\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/langchain-academy/venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:906\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    903\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    904\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    905\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m906\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    907\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    908\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    909\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    910\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    911\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    912\u001b[39m         )\n\u001b[32m    913\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    914\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/langchain-academy/venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:1195\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1193\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1194\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1195\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1196\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1197\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1198\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1199\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/langchain-academy/venv/lib/python3.11/site-packages/langchain_mistralai/chat_models.py:631\u001b[39m, in \u001b[36mChatMistralAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, stream, **kwargs)\u001b[39m\n\u001b[32m    629\u001b[39m message_dicts, params = \u001b[38;5;28mself\u001b[39m._create_message_dicts(messages, stop)\n\u001b[32m    630\u001b[39m params = {**params, **kwargs}\n\u001b[32m--> \u001b[39m\u001b[32m631\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompletion_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    632\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\n\u001b[32m    633\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    634\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_chat_result(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/langchain-academy/venv/lib/python3.11/site-packages/langchain_mistralai/chat_models.py:555\u001b[39m, in \u001b[36mChatMistralAI.completion_with_retry\u001b[39m\u001b[34m(self, run_manager, **kwargs)\u001b[39m\n\u001b[32m    552\u001b[39m     _raise_on_error(response)\n\u001b[32m    553\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response.json()\n\u001b[32m--> \u001b[39m\u001b[32m555\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_completion_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/langchain-academy/venv/lib/python3.11/site-packages/tenacity/__init__.py:338\u001b[39m, in \u001b[36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    336\u001b[39m copy = \u001b[38;5;28mself\u001b[39m.copy()\n\u001b[32m    337\u001b[39m wrapped_f.statistics = copy.statistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/langchain-academy/venv/lib/python3.11/site-packages/tenacity/__init__.py:477\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    475\u001b[39m retry_state = RetryCallState(retry_object=\u001b[38;5;28mself\u001b[39m, fn=fn, args=args, kwargs=kwargs)\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/langchain-academy/venv/lib/python3.11/site-packages/tenacity/__init__.py:378\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    376\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/langchain-academy/venv/lib/python3.11/site-packages/tenacity/__init__.py:400\u001b[39m, in \u001b[36mBaseRetrying._post_retry_check_actions.<locals>.<lambda>\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    398\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_post_retry_check_actions\u001b[39m(\u001b[38;5;28mself\u001b[39m, retry_state: \u001b[33m\"\u001b[39m\u001b[33mRetryCallState\u001b[39m\u001b[33m\"\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.iter_state.is_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.retry_run_result):\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m         \u001b[38;5;28mself\u001b[39m._add_action_func(\u001b[38;5;28;01mlambda\u001b[39;00m rs: \u001b[43mrs\u001b[49m\u001b[43m.\u001b[49m\u001b[43moutcome\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    401\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    403\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.after \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/concurrent/futures/_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/langchain-academy/venv/lib/python3.11/site-packages/tenacity/__init__.py:480\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    478\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m         result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[32m    482\u001b[39m         retry_state.set_exception(sys.exc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/langchain-academy/venv/lib/python3.11/site-packages/langchain_mistralai/chat_models.py:552\u001b[39m, in \u001b[36mChatMistralAI.completion_with_retry.<locals>._completion_with_retry\u001b[39m\u001b[34m(**kwargs)\u001b[39m\n\u001b[32m    550\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m iter_sse()\n\u001b[32m    551\u001b[39m response = \u001b[38;5;28mself\u001b[39m.client.post(url=\u001b[33m\"\u001b[39m\u001b[33m/chat/completions\u001b[39m\u001b[33m\"\u001b[39m, json=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m552\u001b[39m \u001b[43m_raise_on_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    553\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response.json()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/langchain-academy/venv/lib/python3.11/site-packages/langchain_mistralai/chat_models.py:172\u001b[39m, in \u001b[36m_raise_on_error\u001b[39m\u001b[34m(response)\u001b[39m\n\u001b[32m    167\u001b[39m error_message = response.read().decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    168\u001b[39m msg = (\n\u001b[32m    169\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError response \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    170\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mwhile fetching \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_message\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    171\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m httpx.HTTPStatusError(\n\u001b[32m    173\u001b[39m     msg,\n\u001b[32m    174\u001b[39m     request=response.request,\n\u001b[32m    175\u001b[39m     response=response,\n\u001b[32m    176\u001b[39m )\n",
      "\u001b[31mHTTPStatusError\u001b[39m: Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"object\":\"error\",\"message\":\"Service tier capacity exceeded for this model.\",\"type\":\"service_tier_capacity_exceeded\",\"param\":null,\"code\":\"3505\"}",
      "During task with name 'assistant' and id '0b8c33f3-c16d-bedd-b540-802f0be752bf'"
     ]
    }
   ],
   "source": [
    "for event in graph.stream(None, thread, stream_mode=\"values\"):\n",
    "    event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f91a0c-7cc1-4437-adc7-b36abb29beb1",
   "metadata": {},
   "source": [
    "Теперь давайте объединим это с конкретным шагом подтверждения пользователем, который принимает пользовательский ввод."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95a0eb50-66e3-4538-8103-207aae175154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiply 2 and 3\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (zwT8rlIXw)\n",
      " Call ID: zwT8rlIXw\n",
      "  Args:\n",
      "    a: 2\n",
      "    b: 3\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to call the tool? (yes/no):  yes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (zwT8rlIXw)\n",
      " Call ID: zwT8rlIXw\n",
      "  Args:\n",
      "    a: 2\n",
      "    b: 3\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "6\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Multiplying 2 and 3 gives 6.\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "initial_input = {\"messages\": HumanMessage(content=\"Multiply 2 and 3\")}\n",
    "\n",
    "# Thread\n",
    "thread = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Run the graph until the first interruption\n",
    "for event in graph.stream(initial_input, thread, stream_mode=\"values\"):\n",
    "    event['messages'][-1].pretty_print()\n",
    "\n",
    "# Get user feedback\n",
    "user_approval = input(\"Do you want to call the tool? (yes/no): \")\n",
    "\n",
    "# Check approval\n",
    "if user_approval.lower() == \"yes\":\n",
    "    \n",
    "    # If approved, continue the graph execution\n",
    "    for event in graph.stream(None, thread, stream_mode=\"values\"):\n",
    "        event['messages'][-1].pretty_print()\n",
    "        \n",
    "else:\n",
    "    print(\"Operation cancelled by user.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b8ff8762-6fa1-4373-954a-e7f479ee0efb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Точки прерывания с LangGraph API\n",
    "\n",
    "**⚠️ Внимание**\n",
    "\n",
    "После создания этих видео мы обновили Studio, и теперь её можно запускать локально и открывать в браузере. Это предпочтительный способ работы со Studio вместо использования Desktop App, показанного в видео. Теперь она называется _LangSmith Studio_ вместо _LangGraph Studio_. Подробные инструкции по настройке доступны в руководстве \"Начало работы\" в начале курса. Описание Studio можно найти [здесь](https://docs.langchain.com/langsmith/studio), а конкретные детали по локальному развертыванию — [здесь](https://docs.langchain.com/langsmith/quick-start-studio#local-development-server).\n",
    "\n",
    "Чтобы запустить локальный сервер разработки, выполните следующую команду в терминале в директории `/studio` этого модуля:\n",
    "\n",
    "```\n",
    "langgraph dev\n",
    "```\n",
    "\n",
    "Вы должны увидеть следующий вывод:\n",
    "```\n",
    "- 🚀 API: http://127.0.0.1:2024\n",
    "- 🎨 Studio UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024\n",
    "- 📚 API Docs: http://127.0.0.1:2024/docs\n",
    "```\n",
    "\n",
    "Откройте браузер и перейдите по URL-адресу **Studio UI**, указанному выше.\n",
    "\n",
    "LangGraph API [поддерживает точки прерывания](https://docs.langchain.com/langsmith/add-human-in-the-loop)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63c2eaf1-6b8b-4d80-9902-98ae5587bcf9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    raise Exception(\"Unfortunately LangGraph Studio is currently not supported on Google Colab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb1dd890-c216-4802-9e33-b637e491e144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the URL of the local development server\n",
    "from langgraph_sdk import get_client\n",
    "client = get_client(url=\"http://127.0.0.1:2024\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e80d969-d065-45d7-8bfc-a403a0a1079b",
   "metadata": {},
   "source": [
    "Как показано выше, мы можем добавить `interrupt_before=[\"node\"]` при компиляции графа, который работает в Studio.\n",
    "\n",
    "Однако при работе с API вы также можете передать `interrupt_before` непосредственно в метод stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de9c5017-3a15-46f6-8edf-3997613da323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Receiving new event of type: metadata...\n",
      "--------------------------------------------------\n",
      "Receiving new event of type: values...\n",
      "{'content': 'Multiply 2 and 3', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': 'e94f337e-2809-4a82-acb3-0a159a37c8f8'}\n",
      "--------------------------------------------------\n",
      "Receiving new event of type: values...\n",
      "{'content': '', 'additional_kwargs': {'tool_calls': [{'id': 'lLtG2uPiD', 'function': {'name': 'multiply', 'arguments': '{\"a\": 2, \"b\": 3}'}, 'index': 0}]}, 'response_metadata': {'token_usage': {'prompt_tokens': 273, 'total_tokens': 290, 'completion_tokens': 17}, 'model_name': 'mistral-small-latest', 'model': 'mistral-small-latest', 'finish_reason': 'tool_calls', 'model_provider': 'mistralai'}, 'type': 'ai', 'name': None, 'id': 'lc_run--8c941388-a618-4575-b8ea-2ef0cb07e8bf-0', 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'lLtG2uPiD', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 273, 'output_tokens': 17, 'total_tokens': 290}}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "initial_input = {\"messages\": HumanMessage(content=\"Multiply 2 and 3\")}\n",
    "thread = await client.threads.create()\n",
    "async for chunk in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    assistant_id=\"agent\",\n",
    "    input=initial_input,\n",
    "    stream_mode=\"values\",\n",
    "    interrupt_before=[\"tools\"],\n",
    "):\n",
    "    print(f\"Receiving new event of type: {chunk.event}...\")\n",
    "    messages = chunk.data.get('messages', [])\n",
    "    if messages:\n",
    "        print(messages[-1])\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64272d1-c6ee-435f-9890-9b6c3525ca6c",
   "metadata": {},
   "source": [
    "Теперь мы можем продолжить выполнение с точки прерывания, как мы делали ранее, передав `thread_id` и `None` в качестве входных данных!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76284730-9c90-46c4-8295-400a49760b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Receiving new event of type: metadata...\n",
      "--------------------------------------------------\n",
      "Receiving new event of type: values...\n",
      "{'content': '', 'additional_kwargs': {'tool_calls': [{'id': 'lLtG2uPiD', 'function': {'name': 'multiply', 'arguments': '{\"a\": 2, \"b\": 3}'}, 'index': 0}]}, 'response_metadata': {'token_usage': {'prompt_tokens': 273, 'total_tokens': 290, 'completion_tokens': 17}, 'model_name': 'mistral-small-latest', 'model': 'mistral-small-latest', 'finish_reason': 'tool_calls', 'model_provider': 'mistralai'}, 'type': 'ai', 'name': None, 'id': 'lc_run--8c941388-a618-4575-b8ea-2ef0cb07e8bf-0', 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'lLtG2uPiD', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 273, 'output_tokens': 17, 'total_tokens': 290}}\n",
      "--------------------------------------------------\n",
      "Receiving new event of type: values...\n",
      "{'content': '6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': '3c9713c4-c8f0-471a-ad8f-988bf3d7b137', 'tool_call_id': 'lLtG2uPiD', 'artifact': None, 'status': 'success'}\n",
      "--------------------------------------------------\n",
      "Receiving new event of type: values...\n",
      "{'content': 'The result of multiplying 2 and 3 is 6.', 'additional_kwargs': {}, 'response_metadata': {'token_usage': {'prompt_tokens': 311, 'total_tokens': 325, 'completion_tokens': 14}, 'model_name': 'mistral-small-latest', 'model': 'mistral-small-latest', 'finish_reason': 'stop', 'model_provider': 'mistralai'}, 'type': 'ai', 'name': None, 'id': 'lc_run--0a1ff189-1147-4848-87ef-8a0b567970cd-0', 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 311, 'output_tokens': 14, 'total_tokens': 325}}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "async for chunk in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    \"agent\",\n",
    "    input=None,\n",
    "    stream_mode=\"values\",\n",
    "    interrupt_before=[\"tools\"],\n",
    "):\n",
    "    print(f\"Receiving new event of type: {chunk.event}...\")\n",
    "    messages = chunk.data.get('messages', [])\n",
    "    if messages:\n",
    "        print(messages[-1])\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4575970f-42e2-4d03-b18a-aacaa8233b53",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
